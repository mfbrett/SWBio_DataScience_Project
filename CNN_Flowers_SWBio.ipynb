{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mfbrett/SWBio_DataScience_Project/blob/main/CNN_Flowers_SWBio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da3c0815-fc40-413b-a9b7-ebf37149fe05",
      "metadata": {
        "id": "da3c0815-fc40-413b-a9b7-ebf37149fe05"
      },
      "source": [
        "# Using CNN analysis for use in Species ID in Ecological Datasets\n",
        "\n",
        "A script to differentiate between the 5 flower species of the tf_flowers dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import required packages and databases\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# load and split tensorflow 'tf_flowers' dataset into training and validation datasets\n",
        "(train_ds, val_ds), metadata = tfds.load(\n",
        "    'tf_flowers',\n",
        "    split=['train[:70%]', 'train[70%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "# check the number of classes to identify (how many kinds of flower are in the dataset):\n",
        "num_classes = metadata.features['label'].num_classes\n",
        "print(\"Number of classes =\", num_classes)\n",
        "\n",
        "# retreiving an image example:\n",
        "get_label_name = metadata.features['label'].int2str\n",
        "image, label = next(iter(train_ds))\n",
        "_ = plt.title(get_label_name(label))\n",
        "_ = plt.imshow(image, cmap=plt.cm.binary)\n",
        "_ = plt.colorbar()\n"
      ],
      "metadata": {
        "id": "r9SAxJOgMHr6"
      },
      "id": "r9SAxJOgMHr6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reformatting images and creating batches**\n"
      ],
      "metadata": {
        "id": "2UVG5Dlk_FJt"
      },
      "id": "2UVG5Dlk_FJt"
    },
    {
      "cell_type": "code",
      "source": [
        "# check the image shape data in the unmodified dataset\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break \n",
        "# Shows only 3 columns of data, needs one more column to fit model\n",
        "# Additionally, the images in the dataset are of different sizes\n",
        "\n",
        "# Resize image RGB data to 0-1 scale instead of 0-255,\n",
        "# and resize images to measure 224 x 224 pixels\n",
        "IMAGE_RES = 224 # Change IMAGE_RES to alter image size (smaller images reduce model run time)\n",
        "def normalize_img(image, label):\n",
        "    image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "    return image, label\n",
        "\n",
        "#To reconfigure the data and make training and validation batches size 32\n",
        "batch_size = 32\n",
        "train_batches = train_ds.shuffle(2569//4).map(normalize_img).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "val_batches = val_ds.map(normalize_img).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Print new shape of data with extra column\n",
        "print(train_batches) \n",
        "print(val_batches)\n",
        "# Print RGB values - should now be between 0 and 1\n",
        "print(np.min(first_image), np.max(first_image)) \n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "4EeoouVp_Eol"
      },
      "id": "4EeoouVp_Eol",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b917b9a6-fb1e-479e-b190-623c7e5e7ca1",
      "metadata": {
        "id": "b917b9a6-fb1e-479e-b190-623c7e5e7ca1"
      },
      "source": [
        "**Building the model:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea541dde-263b-43fa-899b-d486153894f2",
      "metadata": {
        "id": "ea541dde-263b-43fa-899b-d486153894f2"
      },
      "outputs": [],
      "source": [
        "num_classes = 5\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation='relu'), # second convolution and pooling layers \n",
        "  tf.keras.layers.MaxPooling2D(), \n",
        "  tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation='relu'), # second convolution and pooling layers \n",
        "  tf.keras.layers.MaxPooling2D(), \n",
        "  tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation='relu'), # third convolution and pooling layers \n",
        "  tf.keras.layers.MaxPooling2D(),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'), # Adds a dense layer of 128 neurons\n",
        "  tf.keras.layers.Dropout(0.4), # Adds a dropout layer, to avoid overfitting\n",
        "  tf.keras.layers.Dense(num_classes, activation='softmax') # Adds a final layer with the number of classes (5)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting and Running the Model:**"
      ],
      "metadata": {
        "id": "39yiVaIxB46Q"
      },
      "id": "39yiVaIxB46Q"
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  loss=\"sparse_categorical_crossentropy\",\n",
        "  optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epochs = 5 # Increase the number of epochs and see what affect this has on model accuracy of predicitons.\n",
        "\n",
        "model_fit=model.fit(\n",
        "  train_batches,\n",
        "  validation_data=val_batches,\n",
        "  epochs=epochs\n",
        ")\n",
        "\n",
        "model_fit # Current model run tim with 5 epochs is around 15 minutes.\n"
      ],
      "metadata": {
        "id": "I2-9oLCHvPh6"
      },
      "id": "I2-9oLCHvPh6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Current model returns a successful ID rate of 0.63\n"
      ],
      "metadata": {
        "id": "WT6oq2gdFfRT"
      },
      "id": "WT6oq2gdFfRT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plotting the model 'learning' graph to observe accuracy through time**"
      ],
      "metadata": {
        "id": "gcy0pWGoOcWs"
      },
      "id": "gcy0pWGoOcWs"
    },
    {
      "cell_type": "code",
      "source": [
        "acc = model_fit.history['accuracy']\n",
        "val_acc = model_fit.history['val_accuracy']\n",
        "loss = model_fit.history['loss']\n",
        "val_loss = model_fit.history['val_loss']\n",
        "epochs_range = 5\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='upper left')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WXw2rYL8Ofz6"
      },
      "id": "WXw2rYL8Ofz6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating another batch of images from the tf_flower dataset, and using the trained model to predict flower IDs"
      ],
      "metadata": {
        "id": "j1dtg9LnWaXm"
      },
      "id": "j1dtg9LnWaXm"
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = np.array(metadata.features['label'].names)\n",
        "image_batch, label_batch = next(iter(train_batches))\n",
        "image_batch = image_batch.numpy()\n",
        "label_batch = label_batch.numpy()\n",
        "predicted_batch = model.predict(image_batch)\n",
        "predicted_batch = tf.squeeze(predicted_batch).numpy()\n",
        "predicted_ids = np.argmax(predicted_batch, axis=-1)\n",
        "predicted_class_names = class_names[predicted_ids]"
      ],
      "metadata": {
        "id": "wLfy1THRWdtr"
      },
      "id": "wLfy1THRWdtr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, visualise the predictions of the model"
      ],
      "metadata": {
        "id": "yY8oJjBLWjhJ"
      },
      "id": "yY8oJjBLWjhJ"
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10)) \n",
        "for n in range(16): # Increase the range to see more image results (may need to also increase figsize in the previous line, if this becomes too crowded)\n",
        "    plt.subplot(4,4,n+1) # alter the dimensions of the grid plot\n",
        "    plt.subplots_adjust(hspace = 0.3)\n",
        "    plt.imshow(image_batch[n])\n",
        "    color = \"green\" if predicted_ids[n] == label_batch[n] else \"red\" # colour labels according to correct ID by model, or not\n",
        "    plt.title(predicted_class_names[n].title(), color=color)\n",
        "    plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\") # Title"
      ],
      "metadata": {
        "id": "syvehtsBWebl"
      },
      "id": "syvehtsBWebl",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "CNN_Flowers_SWBio.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}